\chapter{Evaluation}
This section evaluates and discusses the implementations from the thesis so far, setting up some quantifiable goals and raises some issues that needs to be solved before in order to improve the method.
\section{Parallelism}
A section on multiple actors and race conditions. How do you create a use case that contains multiple simultaneous instances of actors that perform the same action synchronously? Basically asserting parallel properties.\todo{.\\turn this into a real section}\\\\
We have a use case, where two Receptionist actor battles for the same call. In order to test this, we may wish to describe the scenario like so -- assuming a call is has arrived and is ready for pickup:
\begin{enumerate}
 \item Receptionist 1 tries to pickup call
 \item Receptionist 2 tries to pickup call
 \item Call is assigned to either Receptionist
\end{enumerate}
%TODO add sequence diagram.
A postcondition may read ``The call is assigned to \emph{only} one receptionist'', in order to emphasize on the actual intended behavior of the system, but the description above should be sufficient.\\
Studying the use case a bit closer, what is actually implied is that 1. happens simultaneously with 2. In practice, it would mean that a test would have to emulate the simultaneous behavior by spawning multiple threads and collecting their return values once they have terminated. But there is another problem with the scenario above, which is that the test tools do not know when to parallelize. As of now, every entry in a use case scenario is modeled as a synchronous action and will wait until the entry has completed its execution before starting the next one.\\\\
A method for solving this, is to add the asynchronism in the mapped test code, but this is a very bad idea. This would lead to very unexpected behavior if requirements change in the specific block. This would lead to treads being spawned, expecting to perform a specific action that no longer existed in the requirements, perhaps deadlocking while waiting for an event to happen -- or change the state of the system that would lead an error later in the test.\\
A better way of solving it, is to add a keyword. For instance \textbf{simultaneously}. So the use case would then read;
\begin{enumerate}
 \item Receptionist 1 tries to pickup call
 \item Receptionist 2 tries to pickup call \textbf{simultaneously}
 \item Call is assigned to either Receptionist
\end{enumerate}
Making the keyword refer in 2. refer to the previous entry, 1. This feature is neither implemented, nor conceptualized further, but included in the discussion as it is a actual problem that was encountered during the development of the 2nd iteration of the tests. There has been developed an \emph{ad-hoc} test that uses the spawn-threads-and-collect method introduced above so there exists a technical solution for the problem.
%\section{Applicablity to different methodologies} See http://en.wikipedia.org/wiki/Requirements_analysis
% Waterfall, Prototype model, Incremental, Iterative, V-Model, Spiral, Scrum, Cleanroom, RAD ...

\subsection{Side benefits}
%One of the major benefits is that it makes other black-box tests easier, as we can re-use components from the framework.

% Further work
%  - Misuse case
%  - Validating event chain against a state machine (automaton).
%  - Executable activity diagrams - knieke2010 
% Treating the system global state enforces a notion within the programmer how the specific activity acutally mutates the global state of the system.
Writing tests is generally easier. Especially integration tests that asserts that an edge case is not reached. The code becomes very verbose in the way that you state the test from the point of view of an actor performing an action.

Another side benefit from having use cases written as tests, whether they are generated or not, is that a gives new developers a good reference point on how the system is intended to work. This is because of the fact that tests are implicitly usage patterns.

\subsection{Differences between first and second iteration}
In the first implementation of the test tools (see section \ref{sec:1st-iteration-test-specification}), there was no shared knowledge of the domain. The tests were written in a different programming language than the main codebase, and interfacing was manual -- even though the test case generation were automated.
The second iteration also treated tests as an intricate part of the main project, rather than an auxiliary part.
\begin{figure}[!hbpt]
\centering
\includegraphics[width=1.0\textwidth]{\imgdir jenkins-build-trend-interation-1}
\caption{Iteration 1 Jenkins build trend. Blue area is total tests, and red area is failures}
\label{fig:jenkins-build-trend-interation-1}
\end{figure}


\begin{figure}[!hbpt]
\centering
\includegraphics[width=1.0\textwidth]{\imgdir jenkins-build-trend-interation-2}
\caption{Iteration 2 Jenkins build trend. Blue area is total tests, and red area is failures}
\label{fig:jenkins-build-trend-interation-2}
\end{figure}


\section{Feasibility}
Iteration 1 build trend in figure \ref{fig:jenkins-build-trend-interation-1}\footnote{Image quality is low, but as the Jenkins server that ran the test has been \emph{physically} garbage collected, it was the best that could be procured.}....

Parameters that should be measured; LOC ratio; test tools; Phonio is around 2kLOC and neglecatable

\begin{table}[!htbp]
\begin{tabular}{ | l | r | r | r |}
   \hline
   Project        & Total (kLoc) & Test support (kLoc) & Overhead \\ \hline
   Test framework & 8.9          & 1.1                 & 10\%     \\
   Phonio         & 2            & 2                   & 100\%    \\
   \hline
   \hline
   Total          & 10.9         & 3.1                 & 28\%     \\
   \hline
\end{tabular}
\caption{Test framework metrics}
\label{tab:test_metrics}
\end{table}
   
 is \~8.5kLOC and kLOC of these lines are code that wraps the framework. The ratio is then roughly around  written code lines.

Model framework is also around 8kLOC and is reused in both the client and the server.
%How much effort is there involved in changing requirements, or implementation.
%Discuss code change on different levels; interface (component), function or data model.
%is this always possible? Are we lucky to have found a good fit for this procedure? Which cases could be thought, not to support this method?
%TODO note; 
LOC isn't all, and coverage certainly isn't all either\cite{fraser2013does}.
\subsection{Relationship to TDD}
In practice; the approach presented in this thesis is a variant of TDD, but injects some elements from MDE and increases the test coverage by automatically generating the tests from use case branches.

%Important bit.

%another note; it was a good experience for me, as a software engineer to be able communicate how I wanted the system to interact internally via tests. It is easier for code-oriented people to relate to code, rather than diagrams and designs.

\subsection{Is if feasible}
Basically; no. Can it be used? To some extent. The process is nice, but the mapping simply unfolds into a too large state space with a stucture so complex that is impossible for an end-user to specify it, and very hard for a trained professional to elaborate it. It may be feasible once model-based software engineering reaches a level where behavioral model can be applied to domain models, and thus ...
%As of now, an ad-hoc templating system is in place. A real templating system should be used in a real product.

\section{Related work}
Using model checking techniques to generate tests from requirements\cite{gargantini1999using}

\subsection{Recommended test framework guidelines}
%Use allocation pools
%Use interfaces a objects.

\section{Caveats}
The system and test system has been developed by the same group of people, which have also played a large role in the use cases creation and refinement process. This is problematic when the general applicability of the approach presented in this thesis needs to be evaluated. Having the same people work on requirements, implementation and tests lead to a unified understanding of the system as a whole, and a very short path from requirement change, to implementation change. While this is generally a good thing, it does not scale to larger projects, and important domain-specific details may unknowingly go undocumented, as everyone has a common understanding of how things work overall. The problem with this, is also that requirements may have an ``artificial feel'', in the way that they reflect the actual workings of the system under development, rather than the intended workings.\\\\
For this evaluation, it means that our requirements may be better suited for acceptance-test-writing than others, trying the same approach. It can however be argued, that as any (good) requirement should be testable\cite{hull2010requirements}, then it shouldn't matter significantly how the project groups are structured.