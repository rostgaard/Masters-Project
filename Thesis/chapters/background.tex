\chapter{Background}
\label{ch:background}
This chapter provides a brief introduction to software testing, test-driven development and how these relate to, and differ from this project. It also provides the historical background and motivation for the idea that eventually became the topic of this thesis. It also gives a brief overview of the design and implementation of the case study system used in this thesis, why we chose to perform the tests on the level that we did, and a brief overview on how it was done. This overview is continued in the next chapter.

\section{Software testing}
In software engineering, continuous testing is one of the most effective weapons against software bugs. Many efforts have been made on automating test generation and test execution, and to enforce rigorous manual test writing by developers. This chapter outlines some of the basic concepts handled in this thesis, and discusses the application and similarities to the approach in this thesis, of them.

\subsection{Testing terminology}
The terminology described here is provided, either because the term is used in the thesis, or for completeness -- i.e. black-box/white-box testing.
\begin{description}
  \item[Test coverage:] The tests coverage is an indication of how many of the branches system is actually covered by the tests. So, a simple function with a single \emph{if-else} branch, that had a test that covered only the \emph{if} branch would have a coverage of 50\%. If there was also a test for the \emph{else} branch, the coverage would reach 100\%. Test coverage applies to every level of testing, from acceptance tests to unit tests.
  \item[White-box test:] A white-box test treats the system as a transparent box where all the internals are known. From these known internals, tests can be written to take a specific code path within the component under test. Unit tests are an example of a white-box test, as it tests the known internals of the unit. In the case study system, white-box tests are used to verify API's and system functionality -- effectively testing multiple API's in a single test.
  \item[Black-box test:] Treats the system as an unknown entity which responds to external stimuli. Nothing is known about the internals of the entity, and by by applying the stimuli, the entity will respond -- hopefully -- in the expected way. The Stimuli-organism-response (figure \ref{fig:sor-model}), which is used areas such as behavioral psychology, graphically depicts the concept very well.
  \item[Unit test:] Is a detailed test of a single unit in the system. While the size of the unit is not strictly defined, a unit is typically a single file or class in software systems. A unit test is a white-box test that focus on broad test coverage.
  \item[Integration test:] Is a test that treats a component, or set of components as a combined entity, and tests it as a black-box system. Integration testing is linked to functional requirements, but may also refer to non-functional requirements, such as behavior under load -- which is known is stress-testing.
  \item[Test harness:] An artificial environment that surrounds a test, supplying it with the resources and API's it needs. An example of a resource could be a database layer that supplies the test with the objects it needs. The harness does not need to provide real objects, but is free to return mock objects to the test, rather than having to deal with actually connecting to a database.
  \item[Acceptance test:] An acceptance test is a test conducted to determine if the requirements of a specification or contract are met. If the contract specified that a ship that could float was to be built, the acceptance test would be to put it in the water and see if floats. If so; the acceptance test was a success.
\end{description}
\begin{figure}[!htbp]
  \centering
  \includegraphics[scale=0.6]{\imgdir sor-model}
  \caption{Stimuli-organism-response model. Used -- for instance -- in psychology, but is analogous black-box testing}
  \label{fig:sor-model}
\end{figure}
\subsection{Test-driven development}
\label{ssec:test-driven-development}
A development methodology that emerged around the millennium, and have been looking very promising, is test-driven development. I focuses on -- as the name would also implicate -- tests before anything else. The basic work-flow is to first write tests, then refactor the code base of the system under development until the test passes. Then, to make sure the refactored code does not break existing functionality, all the previously written tests must be run. This work-flow is illustrated in the flow chart shown in \ref{fig:test-driven-development-flow}.\medskip
\begin{figure}[!htbp]
\centering
\includegraphics[scale=0.6]{\imgdir test-driven-development-flow}
\caption{Basic work-flow of test-driven development}
\label{fig:test-driven-development-flow}
\end{figure}
\noindent Some of the arguments for using test-driven development is that it enables continuous regression testing. It focuses strongly on building the object and components that are needed rather than the ones that are thought to be needed. And it also lowers the gap between component design, and feedback.\cite{george2003}. By feedback is meant developer feedback -- whether the component works or not.\smallskip

\noindent Test-driven development, in its nature, encourages code to be written testable. If a test is written prior to the code, then -- obviously -- the code written will be testable, or it will not pass the tests that originated it. This often means better code reuse and smaller, more loosely coupled components. This is probably due to the fact that when you write tests, it is often the case that you repeat some actions over and over again.\medskip

\noindent In this thesis, the methodology used is similar to the one found in test-driven development, in the way that you \emph{can} build tests from your use cases before the implementation. But unlike test-driven development it does dictate a specific point in development process where you should add the tests.\\
Instead it focuses on a tool-assisted generation of tests scopes to achieve a very broad coverage of requirements. So basically, it gives you the outline of what to test, and which domain concepts are needed for the test.

\subsection{Continuous integration}
Continuous integration is a methodology, that that supplements test-driven development quite well. In essence, it is an automated service that continously runs tests on code, or produce new artifact (binaries) from it. This is done either periodically, (nightly, weekly, monthly) or triggered whenever developer makes a change to the code base.

\section{Case study system}
\label{sec:case-study-system}
% Make a point on why this section is in the thesis. IT EVALUATES THE VALUE OF THE SYSTEM AS USE CASE SYSTEM.
Back in the fall of 2011, a physicist, an electrical engineer a systems programmer, three entrepreneurs and a software engineering student founded a small business. I was created to solve one grave problem that the entrepreneurs had; their current software system was becoming a larger and larger annoyance to them due to lack of upgrades and existing bugs that was never going to be fixed. The latter was due to the fact that the company supporting it, went bankrupt. Thus, a plan was laid to re-engineer a system that would serve as a drop-in replacement for their current one -- only this time as an open source system, so that at least there was a possibility to hand over support contracts to other suppliers, avoided their previous vendor lock-in.\medskip

\noindent The three entrepreneurs were in the business of ``reception hosting''. About one year after, the first conceptual prototype emerged, and by the end of 2013, an alpha version of the product was ready to be tested and hardened for production use. However, due to the high level of asynchronism, and low level of explicit coordination -- which was by design -- regressions became an increasing problem. And when the requirements also started to change, a dire need for automated, and usage-oriented testing became evident.

\subsection{Problem domain glossary}
In this section brief glossary from the problem domain is provided to cover the basic terminology used in the use cases.
\begin{description}
  \item[Customer:] The person in the role of purchasing the software. Assumed to have little or no knowledge about formalism, modeling or programming.
  \item[Contact:] A person or group known to the system -- i.e. previously created with contact details such as phone numbers and email addresses.
  \item[Receptionist:] A user in the system able to handle incoming calls by forwarding them or taking a message.
  \item[Caller:] Anyone who dials a phone number handled by the system. They are not known by the system \textit{a priory}, but the system \textit{may} store previously entered data that serves as a cache.
  \item[PBX:] Private Branch Exchange. A local phone switchboard with built-in logic that determines the flow and destination of a phone call based on dial-plans. Common PBX's capabilities phone queues, Interactive Voice Response (IVR) menus and transfers to either local extension, or external extension. A PBX can be either a special-purpose hardware device, or a software implementation running on regular general-purpose PC hardware. These are referred to as hard- and soft-PBX's, respectively.
  \item[Dial-plan:] A decision system that decides what to with a call from a set of rules, such as ``if the time of day is after 17 o' clock, send to voice mail'', or ``if the callee extension is +45 1234 5678'', put the call straight trough to manager's extension''. The concrete syntax is, of course closer to a programming language, and largely dependent on which PBX is used.
% \item[Domain concept] are usually also present in the mapping, and are usually mapped directly to a class.
%Use case definition: An event that describes behaviors and it's written from a user's perspective.

\end{description}
This glossary is incomplete, with regards to the domain model, but should be sufficient background for interpreting the following use cases.
%TODO the section below is copy-pasted and should be checked and elaborated.
\subsection{Targeted requirements}
We've chosen to focus on the requirements that involves core features from the Receptionist actor point of view. These are, on a high level;
\begin{description}
  \item[Manage calls:] Being able to technically handle calls by performing receive, park, transfer and hangup action.
  \item[Process calls:] Being able to process calls in the context of a dialed reception. This involves having access to data about the reception and its contacts. Being able to dial them, or send them a message.
  \item[Manage message:] Being able to send out messages to contacts, view and resend existing messages.
\end{description}

\subsection{Business model and existing system}
The customer -- the Danish business Responsum -- sells what is called a hosted reception service. Their primary customer segment are other businesses -- both large and small. They employ a number of receptionists that answer phone calls on behalf of these businesses. They perform receptionist tasks as though they were physically located on the premises of those businesses, and have access to a lot of employee data, such as employee information, phone numbers and calendars. This information is continuously maintained by a number of service agents, usually by transferring data between systems manually.\medskip

\noindent Throughout the last ten years, they have used a COTS\footnote{Commercial Off The Shelf} system for this task, that is now showing its age. The system handles phone call routing, call handling (playing greetings and Interactive Voice Response (IVR) menus), presents reception information, manages call routing plans and reception information.
\begin{figure}[!hbpt]
\centering
\includegraphics[width=0.8\textwidth]{\imgdir frontdesk-client-ui}
\caption{Screenshot of the receptionist frontend of the existing system}
\label{fig:frontdesk_screenshot}
\end{figure}
The system is proprietary and abandoned by the developers and is still affected by open bugs and issues. Furthermore, the customers of Responsum are expressing an increasing interest in integrating their own system with the Responsum's system. An example of an integration could be calendar synchronization to lower the manual workload of their service agents.

\subsection{Replacement system}
This section gives a short introduction to the system, its architecture and design and the development process that ultimately motivated the test approach, that is the topic of this thesis.\medskip
\begin{figure}[!hbpt]
\centering
\includegraphics[width=0.8\textwidth]{\imgdir openreception-client-ui}
\caption{Screenshot of the receptionist frontend of the replacement system}
\label{fig:openreception-client-ui}
\end{figure}
\noindent OpenReception web-oriented software/telephony system. It is a system designed to enable receptionists to handle incoming calls, and provide then with the appropriate information so that they may divert or directly handle the calls. The system is designed with high availability in mind with many -- largely independent -- components that are loosely coupled. This limits the Domino-effect, where one faulty component can take down another for no other reason than the fact that they are partitioned together.\\ This component-oriented design has also helped the testing process, as it enabled individual components to be tested and verified independently of the others. A screenshot of the receptionist client of the replacement system can be seen in figure \ref{fig:openreception-client-ui}.

\subsection{Project scope}
%TODO more on this story. Something that leads to the discovery of a structure and The fundamental requirements for the system originates directly from the fact, that is is supposed to be a drop-in replacement of an existing system. It should therefore, as a bare minimum, mirror the features of the existing system.\\
However, the current system has been in production for over ten years and lessons-learned has taught the customer how the system should be improved. Another thing that had to be considered, was the fact that the current system had proven it's stability. Despite being far from perfect, it was certainly usable and provided the technical means for the customer to keep the gears of their business model oiled.
%TODO features broke all the time, when was the system done?, Jenkins was introduced ...
%Use cases are stored in a wiki.

\subsection{Chosen architecture}
Being that the existing system was considered stable, and critical infrastructure, the replacement system was designed with simplicity, and high fault resilience in mind. This means that we tried to provide fall-back mechanisms for most of the system rather than over-eagerly handle every potential fault. The component diagram in figure \ref{fig:component_diagram} shows the architecture, and also gives away some hints about which components are critical, and which are not. Basically, the most critical path is the one that originates from the ``Receptionist Client'' and ends in the ``SIP trunk'' component. These components are considered soft real-time components and are essential for an operation. Fallout of any of these components means direct financial loss for the customer. Fallout of any of the other components (except for SIP Phone, which is actually part of the critical path mentioned above) are tolerated in the design, and the stateless nature of REST (see section \ref{sec:rest}) enables us to maintain caches that can supply clients with the data they need for handling calls.

%Something about fault handling, and about not knowning the "failure space"
%TODO add explanation of the figure, the components and the interfaces.
\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{\imgdir component_diagram}
\caption{Component diagram}
\label{fig:component_diagram}
\end{figure}

\subsection{Implementation}
\todo[inline]{Add nice introduction here}
\subsection{Fault tolerance}
Fault tolerance is built into the system, by first decomposing the system into a lot of smaller parts, reduce the amount the amount of communication (in particular; two-way communication) needed for the system to function, at least partially.

\subsection{Stateless architecture}
\label{sec:rest}
We are, like many others contemporary developers, using REST \footnote{(\textbf{RE}presentational \textbf{S}tate \textbf{T}ransfer)}. It is a reasonably new, and non-standardized (by any comity) techonology for building Web-connected API's. It is a client/server protocol that bases itself upon some very simple principles that enables high scalabilty by it's stateless design, This stateless design enables API providers to partition and cache their resources better, as they do not need to synchronize across partitions.\smallskip

\noindent Automated system testing is also simplified quite a bit, when you don't need to take into account a protocol state.

\subsection{Loose coupling of components} 
In order to minimize the damage of a component failing, we have further atomized the REST API's that we created into smaller services, each responsible for only handling one single task. This is what is, informally, defined as the ``bulkhead pattern''. Originating from naval vessel floating compartments, that was composed of several individual bulkheads. These bulkheads could then be closed off, in case of a leakage in one of them. A parallel to software engineering is to divide your application into separate operating system processes that can be terminated if they start to leak memory, consume excessive amounts of CPU time, or merely lock up. Sometimes, killing worker processes is used as a preemptive method of assuring that processes are kept under control. The Apache HTTPD web server uses this strategy by maximizing the number of requests\footnote{http://httpd.apache.org/docs/2.2/mod/worker.html} a worker process may serve before being terminated and replaced.\smallskip

\noindent In our architecture, we have divided the database operations, dialplan generation, CDR\footnote{Call Detail Records: records of call duration and other information used for invoicing} into dedicated servers, that may be replaced -- even while in production.

\subsection{Reactive application}
\label{ssec:server_notifications}
As an extension of the the stateless client/server architecture, a server notification-push pattern has also been added. This enables us make the user interface reactively update to global state changes, rather than having to poll for these changes periodically. It was the optimal way we could get the client interface to respond to system events in real-time. It ultimately also became an important component in testing, as we could use it as a mean to validate causal relationship of actions and events (for instance; a hangup action on a phone would lead to a hangup event notification).\todo{. maybe add a reference to the causality section}

\subsection{Testing strategy}
\label{sec:background-testing-strategy}
%NOTE This one is moved from first-iterations chapter.
As development progressed, it became increasingly difficult and time consuming to verify the correctness of the implementation by manually running the acceptance tests, which basically involved; performing an incoming call via a phone, picking up the call via the system, accept the call on another phone and then perform the actual use case scenario. This could, for example, be to forward the call and signal an idle state to system. Other issues with this manual approach was that is was time-consuming and was easy to perform in an incorrect order, thus leading to false negatives in test runs. Clearly the project could benefit from investing time in scripting the setup and tearing down of the state which was need to perform the manual tests.
During the progression of the project, it became more and more clear to us that we were constrained by two parameters, in regards to testing:
\begin{itemize}
  \item We needed to verify the the functionality of system as a whole, and argue that it was free of instabilities. This functionality was defined in the use cases.
  \item We had very limited man-hours available and, thus, had to prioritize very aggressively on what level to tests on.
\end{itemize}
\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{\imgdir receptionist_workflow}
\caption{Labeled activity diagram of the basic workflow of a receptionist}
\label{fig:receptionist_workflow}
\end{figure}
Being that the system consisted of a number of loosely coupled components, some of them not under our control, we decided to focus on writing up black-box tests focusing on verifying the behavior of the individual components, or multiple connected components.
Furthermore, we wanted to automate this using a continuous integration service that could run our tests for us, and provide us with reports on regressions, or identified bugs. But first, a proper level of testing had to be chosen.

\subsection{Level of testing}
\label{ssec:level-of-testing}
We chose path of assuming everything worked and, thus,  built tests from the perspective of how it should work. So we basically treated the system as a block-box system and abstract away as many implementation details as possible. For this purpose, we and built a ``robot-receptionist'' and a ``robot-caller''. These ``robots'' acted as clients and connected to the \textbf{REST-Data}, \textbf{REST-Call}, \textbf{REST-SIP} interfaces from figure \ref{fig:component_diagram}.

\subsection{Coverage of testing}
In order to test the system, using the black-box method, we needed to formulate the tests in a way that provided the broadest coverage possible. To achieve this, we crafted a set of activity diagrams from the use cases of the system (see figure \ref{fig:receptionist_workflow}). From this, we could assert that every path of the activity diagram was covered.

\subsection{Generation of tests}
To make sure that all paths were covered, every activity node got labeled. Any unique path through the activity diagram should then correspond to a use case, but more importantly; be realized by a test. To achieve this, we constructed a set of tools that, among other things contained the ``robots'' discussed briefly in section \ref{ssec:level-of-testing}.\medskip

\noindent By letting a continuous integration service automatically re-deploy the software stack and, run our acceptance test (along with a number of integration tests) every time the is any change to the code base, we both strengthen the confidence of the correctness (according to specification) of the software stack, and verify that no regressions arise. The continuous integration server can be found at \url{http://ci.bitstack.dk/}

\section{Summary}
The high level of modularization, and low coupling of components made the system easily testable. Most components could be be tested individually, and some of them emulated. The modularization effectively also led to many well-defined interfaces, which is the basic premise for black-box testing. The project, in itself, is quite suitable for a case study system, from a testing perspective.\medskip

\noindent The use cases of the system are, however, not very complex and may not be able to expose scalability issues in the tool. The already developed ``robot'' programs are, on the other hand, very suitable for building controllable ``robot-actor'' for use in generated tests.\medskip

\noindent Prior to the conceival of the idea for this thesis, the test concept described above was implemented and part of our development. And during the writing of this thesis, a second iteration was written, in order to aid the tool for this thesis. These iterations are described in the next chapter.