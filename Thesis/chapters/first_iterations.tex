\chapter{First iterations}
%Purpose is to provide anecdotal background for the theoretical descussion.
%First implementation focused on the generation, second focused on the domain.
This section describes the first and second iteration of the test generation tool. The first iteration was developed using code generation as an experiment that proved itself useful enough to refine. The second refinement was done as part of this thesis, and was linked directly to the shared domain model and interfaces of the system that was exposed in common framework (section \ref{ssec:openreception_framework}). The second iteration created a common ground for the requirements translation project, as many of the actors and concepts that we need to map to is provided to us by it (section \ref{ssec:supporting-test-tools}).\\
This section also covers the motivation and scoping for the tests and test tools. Later on, it explains how it was implemented and refined. The first iteration of the project focused primarily on automating the generation of test, and is highlighted in the plot in figure \ref{fig:project_parameter_plot_1st_iteration}.
\begin{figure}[!htbp]
\centering
\begin{tikzpicture}

% horizontal axis
\draw[->] (0,0) -- (6,0) node[anchor=north,midway] {\small Generation};

% vertical axis
\draw[->] (0,0) -- (0,4) node[anchor=south,rotate=90,midway] {\small Domain-awareness};

\draw (5,0.2) node[circle,fill,inner sep=1pt, fill=dkred,minimum size=0.3cm ,label=above:1st iteration] {};
\draw (1.2,3.0) node[circle,fill,inner sep=1pt, fill=blue, label=above:2nd iteration] {};

% Project
\draw (5,3) node[circle,fill,inner sep=1pt, fill=dkgreen, label=above:Project] {}; 
\end{tikzpicture}
\caption{First iteration focused mainly on generation. The dark red dot highlights the 1st iteration}
\label{fig:project_parameter_plot_1st_iteration}
\end{figure}

\section{Motivation and scope}
During the development of the system, little or no unit tests had prevailed. This  was primarily caused by the very high fluctuation in application architecture, design and implementation. None of the developers were familiar with the development of telephony applications, and lessons-learned frequently affected both design and implementation and quickly made whatever unit tests that was created, obsolescent. Far too much time was spent on refactoring code that, compiled fine, but no longer behaved as it should.\\
Is was mainly the high level of asynchronism of the system, and low level of control with the PBX that made feature regressions a daily pain. Unit tests were of little, or no use, as we were basically writing and testing components, without knowing if they belonged in the system, or not. For this problem; the solution of applying a test-driven development methods seemed very suitable, but we wanted to raise the abstraction level a bit further, and start directly from requirements and test the system as a whole.\\\\
Testing the system as a whole can be done in two ways; either by providing a complete test environment (sometimes called ``test harness'') that emulates the behavior of the interfaces that the component under test requires. In our case, the option of emulating the interface of an entire PBX wasn't really solution for our problem. Basically, if we knew the exact behavior of the PBX and IP-telephony domain, then we would just build the logic to handle it. The best solution we could think of, was to include the PBX as a required -- and included -- component for the component tests.
The second way you can test a system as whole, is to test a deployed instance of the system. But before anything could be tested, we needed to decide what to test.

\subsection{Test specification}
\label{sec:1st-iteration-test-specification}
%TODO Note; the motivation for using the activity diagram, was that is was very simple for the customer to relate to -- without being distracted by the more specific level of use cases. I.e. not much "what happens if".
%TODO Another motivation for creating the tests, and focusing on this actor is that the functionality of this actor is business-breaking if stuff goes wrong.
\begin{figure}[h]
\includegraphics[scale=0.8]{\imgdir receptionist_workflow}
\centering
\caption{Activity diagram for the receptionist actor}
\label{fig:activity_diagram_receptionist}
\end{figure}

In order to derive a which cases should be tested, we -- in a figurative sense --  tore apart an activity diagram and created use cases from them. Then added the missing parts with the help of a representative from customer of the system. Once we had the use cases as a list of actions and alternatives, we had a manuscript that we needed to replay to assert functionality of the system.\\
In order to generate test from this, we estimated that every statement, or line, in the use case could be mapped to a block of manually written source. So, basically, if we had an action that was ``Receptionist dials extension of contact'', we would have a corresponding re-usable function that performed this action. We named this ``the use-case oriented scripting environment'', and used it to write up tests of the system that originated directly from the requirements.

\subsection{Mappings}
Every use case statement was analyzed, and concepts and actors were extracted from them, effectively giving us the minimal requirements for which objects (programming objects) that needed to participate in the test.\\
In the scripting environment, we then outlined the domain actors (such as caller and receptionists). External resources were also needed, and was provided by the main system via services interfaces. The final thing to outline and add to classes were the non-actor domain concepts, such as calls and messages.\\\\
The next step was then to assign every action, precondition and postcondition line a unique identification and map the identification to individual code chunks. We also wanted to generate documentation along with the tests, so the mapping from on entry was done to three separate chunks, each serving its own purpose.
\begin{figure}[!htbp]
\centering
\includegraphics[width=0.60\textwidth]{\imgdir initial_model}
\caption{Class diagram outlining the composition of the initial test-generation model}
\label{fig:first_generation_model}
\end{figure}
\begin{description}
  \item[Visualization:] A graphical presentation of the use case in the form of a sequence diagram. In our specific case, we used a tool called seqdiag, and an example of the input is shown is shown in listing \ref{lst:seqdiag_code_example}. The main concept of this was to provide convenient overview of how, and when, the interaction between the actors happened.
  \item[Documentation:] In the OpenReception project, every bit of the documentation lives in a Wiki which is formatted using Markdown. This meant that we could link the source documents associated with use case to the use cases themselves. Generation of use case documentation in the Wiki was using these document fragments.
  \item[Testing] The final, and most significant part of the system, was the ability to generate use case tests from the actual use cases. This meant that we needed to describe every action in the use case as bit of code and then patch it together using the list of actions, pre- and postconditions provided in the use case descriptions. An example of an assembled is shown in listing \ref{lst:example_python_output}.
\end{description}
\noindent
A class diagram showing the relations between the different components in our initial use case translator is shown in figure \ref{fig:first_generation_model}. It depicts the association between the different types of code fragments, and how they are related to a use case model.
\begin{lstlisting}[language=Bash, caption=Example seqdiag input fragment, label=lst:seqdiag_code_example]

Receptionist ->> System [label = "Dials contact"];
System       ->> Receptionist [label = "Call rejected"];
\end{lstlisting}

\begin{lstlisting}[language=Python, caption=Example generated Python code output, label=lst:example_python_output]
# \${WIKI_URL}
from forward_call import Test_Case
class Sequence_Diagram (Test_Case):
  def test_Run (self):
    self.Preconditions ()
    self.Receptionist_Dial_Contact()
    self.Call_Is_Denied()
    self.Postconditions()

\end{lstlisting}

\noindent
The observant reader will probably already have noticed that this code cannot stand by itself. For instance, the \texttt{self.Receptionist\_Dial\_Contact()} statement references a method found within its own class\footnote{For those unfamiliar with Python, \texttt{self} is a reference to the current object instance, similar to the \texttt{this} keyword in Java.}. In order to keep the code chunk complexity low, we decided to abstract a lot of the complexity into macro functions that were provided to the use case through a framework. Each use case was given it's own programming class that then provided these macro function via class members. Each class would then need to be self-contained and also provide setup/teardown functions, and setup pre and postconditions. The setup and teardown functions were defined as begin technical prerequisites, whereas the pre- and postcondition functions were for setting up the use case prerequisites and would, thus, map to the use case pre- and postconditions.\\\\
\begin{figure}[!h]
\centering
\includegraphics[width=0.25\textwidth]{\imgdir first_generation_class_structure}
\caption{Class diagram outlining the overall hierarchy of executable use cases}
\label{fig:first_generation_class_structure}
\end{figure}
Programing-wise, this was done by adding the needed macro methods required by the use cases to an abstract superclass that represented the overall use case. Each path, or variant, would then be an extension of this superclass. A simplified class diagram illustrating this is shown in figure \ref{fig:first_generation_class_structure}, where you can see that every variant (path of an extension) of a use case may reuse methods from its superclass. Each use case variant must also supply the abstract methods \texttt{run}, \texttt{Precondition} and \texttt{Postcondition} to fulfill the interface.\\
Missing methods, or problems in generated code were identified by static analysis using the pylint tool\footnote{http://www.pylint.org/}.
\newpage
\section{Second iteration}
We soon realized that doing individual mapping for every line was tedious, time consuming and error-prone. Especially due to the fact that a lot of implicit knowledge was needed to perform the manual mapping. An example of this would be to reference a person object in an a scenario action, assuming that it was previously declared in an earlier macro.\\\\
\begin{figure}[!htbp]
\centering
\begin{tikzpicture}

% horizontal axis
\draw[->] (0,0) -- (6,0) node[anchor=north,midway] {\small Automation};

% vertical axis
\draw[->] (0,0) -- (0,4) node[anchor=south,rotate=90,midway] {\small Domain-awareness};

\draw (5,0.2) node[circle,fill,inner sep=1pt, fill=blue, label=above:1st iteration] {};
\draw (1.2,3.0) node[circle,fill,inner sep=1pt, fill=dkred,minimum size=0.3cm ,  label=above:2nd iteration] {};

% Project
\draw (5,3) node[circle,fill,inner sep=1pt, fill=dkgreen, label=above:Project] {}; 

\end{tikzpicture}
\caption{Second iteration involved manually writing up the use case tests while linking it to the domain model, but didn't include any automation}
\label{fig:project_parameter_plot_2nd_iteration}
\end{figure}We thought that if we injected additional domain knowledge into the test framework, would reduce the number of errors associated in mapping the tests manually. Specifically, by moving our macro methods to the appropriate class -- in an object-oriented fashion -- would enable reuse. For example when a sentence states that a receptionist actor hangs up a call, we add a ``hangup'' method to the  ``Receptionist'' class that takes a ``Call'' object as an argument. The second iteration it highlighted in figure \ref{fig:project_parameter_plot_2nd_iteration}. It is built during the course this thesis, and is thus considered an auxiliary part of it.

\subsection{Sharing domain model knowledge}
During the evolution of the software, platform, language and architecture changes eventually landed us in a space where we had the opportunity to use the same programming language both on the sever and the client. We wanted to exploit this initially by sharing the model classes between the server and client, but it soon evolved into a larger framework, also covering interfaces and REST resource definitions. We could now, fairly easy, by re-using the domain classes and interfaces from the framework build tests that with a higher domain awareness than the previous iteration.\\
This section explains the processes of befitting from the models and interface of the framework for a third application: Namely testing. 

\subsection{Framework content}
\label{ssec:openreception_framework}
\begin{figure}[!htbp]
\includegraphics[scale=0.65]{\imgdir framework_example}
\centering
\caption{Example of the framework class structure}
\label{fig:framework_example}
\end{figure}
%TODO mention above figure.
\noindent
The framework is a set of passive classes that is divided, into the following categories (and code libraries). It takes care of tedious low-level tasks such as serialization/deserialization object building from databases and Uri encoding. It is divided into the following different parts;
\begin{description}
  \item[Models:] Every model of the framework is either part of the domain model, or closely related to a concept in it. Each class that is meant to be distributed is provided with serialization and de-serialization methods for use in the service layer.
  \item[Storage:] Abstract interface descriptions. An example is a the interface that dictates which primitives a storage layer for messages must have. In our case, this is CRUD operations (see appendix \ref{appendix:glossary}), and and ``enqueue'' that puts a message into a delivery queue.
  \item[Service:] These classes provide client classes (services from the client point of view), that exposes methods for remote procedure calls. the clients use  use the framework model de-serialization methods to automatically build typed objects on the client side. This eliminates the hassle of having to deal with low-level encoding and decoding. It enables the clients to work directly on the domain objects via the supplied service interfaces.
  \item[Database:] Database access layer. Contains every SQL query functions. The functions casts from database queries to domain objects that may be serialized for transport to remote clients via -- for instance -- HTTP.
  \item[Resource:] Encoding library that turns objects into a REST-resource identifiers. Used to abstract away the Uri encodings on both the client and the server.
\end{description}
The framework served an important purpose in writing the code that modeled the actor behavior needed in the acceptance tests that we wrote.
\subsection{Supporting test tools}
\label{ssec:supporting-test-tools}
In order to perform fully automated end-to-end testing of the system, the framework was not quite enough. A black box test of a system -- in general -- requires external stimuli in order to produce a result.\\\\
So, to perform tests from a use case perspective, we needed to add more domain-awareness to our test environment. We did this writing up classes that corresponded to a caller, callee and receptionist actor and aggregated the needed client interfaces and concepts. Most of this was provided by the framework (see section \ref{ssec:openreception_framework}), such as the user and reception information. But, we also wanted to perform actual phone calls whenever a use case stated that this was what happened. We developed a small software phone, that could be integrated into, into and controlled by, our test tools. On top of that, an abstraction library was created -- PhonIO\footnote{https://github.com/Bitstackers/Phonio}. This library abstracted away the specifics of a phone, exposing just a general interface. This allowed us to scale up tests a lot easier, as we could just add additional soft-phones. It also allowed us to use the tests tools to both assert the functionality of a physical deployment (with hardware phones), and the functionality of an automated test-deployment (using soft-phones). The test system also supplies causality-checkers, such as ``wait-for'' methods that expects a specific event to occur within a bounded time-span.\\\\
\begin{figure}[!htbp]
\centering
\includegraphics[width=0.90\textwidth]{\imgdir component_diagram_with_tests}
\caption{Component diagram -- extended with tests}
\label{fig:component_diagram_with_tests}
\end{figure}The extended component diagram in figure \ref{fig:component_diagram_with_tests} depicts how the supporting test tools fit into the overall architecture of the system. It re-uses the REST interfaces (exposed in the shared framework) and controls phones via the library mentioned before. By reusing the model and interface classes from framework, a lot of test code is reduced significantly.
\subsection{Resource pools}
\label{ssec:resource-pools}
A crucial component that was added to the tests tools were the resource pool. This component has also been found to be important in generation, but this is discussed later on.\\
Tests require resources as part of their test harness -- resources that are available to them prior to the test body -- need to get these from somewhere. For this purpose we defined the abstract component ``resource pool''. For those familiar with manual memory management from -- for example -- the C programming language, will recognize the pattern of explicitly allocating and deallocating resources from the \texttt{malloc/free} system calls. This system is almost identical, however it manage no hold memory blocks -- it manages resources.\\
Resources a quite a broad term, but specifically in our test tools, resources are pre-configured actors; domain objects -- such as user and reception data. Before a test can run, it needs to specify which resources it needs to be able to complete. For instance; a test involving a caller dialing a reception -- handled by a receptionist, needs a caller and reception actor, and reception data. These will be allocated from three separate resource pools that must be available before starting the tests.\\\\
\begin{figure}[!htbp]
\centering
\includegraphics[width=0.50\textwidth]{\imgdir resource_pool}
\caption{Abstract resource pools with specializations}
\label{fig:resource_pool}
\end{figure}There are three different specializations of resource pools in our current implementation of the test tools. These cover a broad variety of scenarios, and should be sufficient for most implementations.
\begin{description}
  \item[Bounded pool:] A Bounded pool hold resources that are limited in the system. For example, our system holds a limited number of configured receptionist actors, and when that last one is allocated, there is no way of acquiring more. The only way to get around it is to manually lower the required number of actors required for a test or add more receptionist actors.
  \item[Unbounded pool:] Any resource that conceptually without an upper bound, it may be realized by a bounded pool. It is either a resource that may be shared (allocated multiple times), or a resource that easy to replicate. For instance, an object that is created from a template.
  \item[Randomizer:] The randomizer is a sort of bastard-concept we introduced in order to spice our tests up with some random inputs. It constructs new random object upon each allocate call, but may be both bounded and unbounded in nature.
\end{description}
These concepts are reused in the next iteration of the tests, which is the refined tests-generation tool.

%TODO add some snibblets of framwork content.